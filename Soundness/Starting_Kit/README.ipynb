{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Kit - Soundness \n",
    "\n",
    "TODOs: \n",
    "- Add detailed description of the challenge\n",
    "- describe your data\n",
    "- describe how you will evaluate\n",
    "- provide instructions to the participants about what they should do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup\n",
    "***\n",
    "`COLAB` determines whether this notebook is running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB='google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # clone github repo\n",
    "    !git clone https://github.com/ihsaan-ullah/M1-Challenge-Class-2024.git\n",
    "\n",
    "    # move to the HEP starting kit folder\n",
    "    %cd M1-Challenge-Class-2024/Soundness/Starting_Kit/\n",
    "\n",
    "    !pip install -q --upgrade sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Imports\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Directories\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./\"\n",
    "# Input data directory to read training data from\n",
    "input_dir = root_dir + \"sample_data/\"\n",
    "# Reference data directory to read test labels from\n",
    "reference_dir = root_dir + \"sample_data/\"\n",
    "# Output data directory to write predictions to\n",
    "output_dir = root_dir + \"sample_result_submission\"\n",
    "# Program directory\n",
    "program_dir = root_dir + \"ingestion_program\"\n",
    "# Score directory\n",
    "score_dir = root_dir + \"scoring_program\"\n",
    "# Directory to read submitted submissions from\n",
    "submission_dir = root_dir + \"sample_code_submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Add directories to path\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(input_dir)\n",
    "sys.path.append(reference_dir)\n",
    "sys.path.append(output_dir)\n",
    "sys.path.append(program_dir)\n",
    "sys.path.append(submission_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Data\n",
    "***\n",
    "1. Load Data\n",
    "2. Preprocess data\n",
    "\n",
    "\n",
    "TODOS:\n",
    "- show data statistics\n",
    "\n",
    "### ⚠️ Note:\n",
    "The data used here is sample data is for demonstration only to get a view of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "      self.df = None\n",
    "\n",
    "      print(\"==========================================\")\n",
    "      print(\"Data\")\n",
    "      print(\"==========================================\")\n",
    "\n",
    "  def load_data(self):\n",
    "    \"\"\"\n",
    "      Loads data from csv file\n",
    "    \"\"\"\n",
    "    print(\"[*] Loading Data\")\n",
    "\n",
    "    # files path\n",
    "    train_data_file = os.path.join(input_dir, 'train.csv')\n",
    "    test_data_file = os.path.join(input_dir, 'test.csv')\n",
    "    train_labels_file = os.path.join(input_dir, 'train.labels')\n",
    "    test_labels_file = os.path.join(reference_dir, 'test.labels')\n",
    "    \n",
    "    # read data\n",
    "    self.train_df = pd.read_csv(train_data_file)\n",
    "    self.test_df = pd.read_csv(test_data_file)\n",
    "\n",
    "    # read labels\n",
    "    with open(train_labels_file, 'r') as file:\n",
    "      self.train_labels = [int(line.strip()) for line in file.readlines()]\n",
    "    with open(test_labels_file, 'r') as file:\n",
    "      self.test_labels = [int(line.strip()) for line in file.readlines()]\n",
    "\n",
    "  def transform_data(self):\n",
    "\n",
    "    print(\"[*] Transforming Data\")\n",
    "    # pre-trained model\n",
    "    self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # train context and references\n",
    "    train_contexts = self.train_df['context_sentences'].tolist()\n",
    "    train_references = (self.train_df['reference_title'] + \" \" + self.train_df['reference_abstract']).tolist()\n",
    "\n",
    "    # test context and references\n",
    "    test_contexts = self.test_df['context_sentences'].tolist()\n",
    "    test_references = (self.test_df['reference_title'] + \" \" + self.test_df['reference_abstract']).tolist()\n",
    "\n",
    "    # Compute train embeddings\n",
    "    train_context_embeddings = self._compute_embeddings(train_contexts)\n",
    "    train_reference_embeddings = self._compute_embeddings(train_references)\n",
    "\n",
    "    # Compute test embeddings\n",
    "    test_context_embeddings = self._compute_embeddings(test_contexts)\n",
    "    test_reference_embeddings = self._compute_embeddings(test_references)\n",
    "\n",
    "    # Calculate cosine similarity scores\n",
    "    cosine_similarity = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "    train_similarity_scores = [cosine_similarity(context, reference) for context, reference in zip(train_context_embeddings, train_reference_embeddings)]\n",
    "    test_similarity_scores = [cosine_similarity(context, reference) for context, reference in zip(test_context_embeddings, test_reference_embeddings)]\n",
    "\n",
    "    self.X_train = train_similarity_scores\n",
    "    self.X_test = test_similarity_scores\n",
    "\n",
    "  def get_train_data(self):\n",
    "    return self.X_train, self.train_labels\n",
    "  \n",
    "  def get_test_data(self):\n",
    "    return self.X_test, self.test_labels\n",
    "\n",
    "  def _compute_embeddings(self, texts):\n",
    "    return self.embeddings_model.encode(texts, convert_to_tensor=False)\n",
    "  \n",
    "  def show_random_sample(self):\n",
    "    random_sample_index = np.random.randint(0, len(self.train_df))\n",
    "    print(\"Example Context sentence\")\n",
    "    print(self.train_df.context_sentences.iloc[random_sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Data\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Initilaize data\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading Data\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Transforming Data\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data.transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Context sentence\n",
      "DNNs have also become powerful tools for many scientific fields, such as medicine, bioinformatics,and astronomy [X], which usually involve massive data volumes.\\nHowever, deep learning still has some significant disadvantages.\n"
     ]
    }
   ],
   "source": [
    "# show random sample from data\n",
    "data.show_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Visualize\n",
    "***\n",
    "TODOs:\n",
    "- visualize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualize():\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        print(\"==========================================\")\n",
    "        print(\"Visualize\")\n",
    "        print(\"==========================================\")\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "\n",
    "    def visualize_data(self):\n",
    "        print(\"Implement this function\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Visualize\n",
      "==========================================\n",
      "Implement this function\n"
     ]
    }
   ],
   "source": [
    "# Initilaize Visualize\n",
    "visualize = Visualize(data=data)\n",
    "visualize.visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Import Submission Model\n",
    "***\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: initializes classifier\n",
    "- `fit`: gets train data and labels as input to train the classifier\n",
    "- `predict`: gets test data and outputs predictions made by the trained classifier\n",
    "\n",
    "\n",
    "In this example code, the `Model` class implements a Gradient Boosting Classifier model. You can find the code in `M1-Challenge-Class-2024/Soundness/Starting_Kit/sample_code_submission/model.py`. You can modify it the way you want, keeping the required class structure and functions there. More instructions are given inside the `model.py` file. If running in Collab, click the folder icon in the left sidebar to open the file browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Program\n",
    "***\n",
    "**`Ingestion program`** is responsible to run the submission of a participant on Codabench platform. **`Program`** is a simplified version of the **Ingestion Program** to show to participants how it runs a submission.\n",
    "1. Train a model on train data\n",
    "2. Predict using Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        # used to keep object of Model class to run the submission\n",
    "        self.model = None\n",
    "        # object of Data class used here to get the train and test sets\n",
    "        self.data = data\n",
    "\n",
    "        # results\n",
    "        self.results = []\n",
    "\n",
    "        print(\"==========================================\")\n",
    "        print(\"Program\")\n",
    "        print(\"==========================================\")\n",
    "    \n",
    "    def initialize_submission(self):\n",
    "        print(\"[*] Initializing Submmited Model\")\n",
    "        self.model = Model()\n",
    "\n",
    "    def fit_submission(self):\n",
    "        print(\"[*] Calling fit method of submitted model\")\n",
    "        X_train, y_train  = self.data.get_train_data()\n",
    "        X_train = np.array(X_train).reshape(-1, 1)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    def predict_submission(self):\n",
    "        print(\"[*] Calling predict method of submitted model\")\n",
    "      \n",
    "        X_test, _ = self.data.get_test_data()\n",
    "        X_test = np.array(X_test).reshape(-1, 1)\n",
    "        self.y_test_hat = self.model.predict(X_test)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Program\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Intiialize Program\n",
    "program = Program(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Initializing Submmited Model\n",
      "[*] - Initializing Classifier\n"
     ]
    }
   ],
   "source": [
    "# Initialize submitted model\n",
    "program.initialize_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Calling fit method of submitted model\n",
      "[*] - Training Classifier on the train set\n"
     ]
    }
   ],
   "source": [
    "# Call fit method of submitted model\n",
    "program.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Calling predict method of submitted model\n",
      "[*] - Predicting test set using trained Classifier\n"
     ]
    }
   ],
   "source": [
    "# Call predict method of submitted model\n",
    "program.predict_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Score\n",
    "***\n",
    "\n",
    "TODOs:\n",
    "- Explain the evaluation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score():\n",
    "\n",
    "    def __init__(self, data, program):\n",
    "\n",
    "        self.data = data\n",
    "        self.program = program\n",
    "\n",
    "        print(\"==========================================\")\n",
    "        print(\"Score\")\n",
    "        print(\"==========================================\")\n",
    "\n",
    "    def compute_scores(self):\n",
    "        print(\"[*] Computing scores\")\n",
    "\n",
    "        _, y_test = self.data.get_test_data()\n",
    "        y_test_hat = self.program.y_test_hat\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_test_hat)\n",
    "        print(f\"Accuracy score: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Score\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize Score\n",
    "score = Score(data=data, program=program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing scores\n",
      "Accuracy score: 0.6570397111913358\n"
     ]
    }
   ],
   "source": [
    "# Compute Score\n",
    "score.compute_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Submissions\n",
    "***\n",
    "\n",
    "### **Unit Testing**\n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission.\n",
    "<br>\n",
    "Keep the sample code simple.<br>\n",
    "\n",
    "<code>python3</code> is required for this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Ingestion Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "### Ingestion Program\n",
      "############################################\n",
      "\n",
      "[*] Loading Data\n",
      "[*] Transforming Data\n",
      "[*] Initializing Submmited Model\n",
      "[*] - Initializing Classifier\n",
      "[*] Calling fit method of submitted model\n",
      "[*] - Training Classifier on the train set\n",
      "[*] Calling predict method of submitted model\n",
      "[*] - Predicting test set using trained Classifier\n",
      "[*] Saving ingestion result\n",
      "\n",
      "---------------------------------\n",
      "[✔] Total duration: 0:38:25.285816\n",
      "---------------------------------\n",
      "\n",
      "----------------------------------------------\n",
      "[✔] Ingestions Program executed successfully!\n",
      "----------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 $program_dir/ingestion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Scoring Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "### Scoring Program\n",
      "############################################\n",
      "\n",
      "[*] Reading predictions\n",
      "[✔]\n",
      "[*] Reading test labels\n",
      "[✔]\n",
      "[*] Computing scores\n",
      "Accuracy Score: 0.6570397111913358\n",
      "[✔]\n",
      "[*] Writing scores\n",
      "[✔]\n",
      "\n",
      "---------------------------------\n",
      "[✔] Total duration: 0:00:00.004887\n",
      "---------------------------------\n",
      "\n",
      "----------------------------------------------\n",
      "[✔] Scoring Program executed successfully!\n",
      "----------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 $score_dir/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare the submission**\n",
    "\n",
    "TODOs:  \n",
    "- The following submission will be submitted by the participants to your competition website. Describe this clearly and point to the competition once your website is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit : Soundness-code_submission_24-01-12-15-27.zip to the competition\n",
      "You can find the zip file in `M1-Challenge-Class-2024/Soundness/Starting_Kit/\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "code_submission = 'Soundness-code_submission_' + the_date + '.zip'\n",
    "zipdir(code_submission, submission_dir)\n",
    "print(\"Submit : \" + code_submission + \" to the competition\")\n",
    "print(\"You can find the zip file in `M1-Challenge-Class-2024/Soundness/Starting_Kit/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9e001b0608738f9411416229c98988c04b997dc526fb61c5e4e084e768e3249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
