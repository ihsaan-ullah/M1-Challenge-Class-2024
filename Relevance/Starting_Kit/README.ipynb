{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Kit - Relevance \n",
    "\n",
    "TODOs: \n",
    "- Add detailed description of the challenge\n",
    "- describe your data\n",
    "- describe how you will evaluate\n",
    "- provide instructions to the participants about what they should do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup\n",
    "***\n",
    "`COLAB` determines whether this notebook is running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB='google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # clone github repo\n",
    "    !git clone https://github.com/ihsaan-ullah/M1-Challenge-Class-2024.git\n",
    "\n",
    "    # move to the HEP starting kit folder\n",
    "    %cd M1-Challenge-Class-2024/Relevance/Starting_Kit/\n",
    "\n",
    "    !pip install -q --upgrade sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Imports\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Directories\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./\"\n",
    "# Input data directory to read training data from\n",
    "input_dir = root_dir + \"sample_data/\"\n",
    "# Reference data directory to read test labels from\n",
    "reference_dir = root_dir + \"sample_data/\"\n",
    "# Output data directory to write predictions to\n",
    "output_dir = root_dir + \"sample_result_submission\"\n",
    "# Program directory\n",
    "program_dir = root_dir + \"ingestion_program\"\n",
    "# Score directory\n",
    "score_dir = root_dir + \"scoring_program\"\n",
    "# Directory to read submitted submissions from\n",
    "submission_dir = root_dir + \"sample_code_submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Add directories to path\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(input_dir)\n",
    "sys.path.append(reference_dir)\n",
    "sys.path.append(output_dir)\n",
    "sys.path.append(program_dir)\n",
    "sys.path.append(submission_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Data\n",
    "***\n",
    "1. Load Data\n",
    "2. Preprocess data\n",
    "\n",
    "\n",
    "TODOS:\n",
    "- show data statistics\n",
    "\n",
    "### ⚠️ Note:\n",
    "The data used here is sample data is for demonstration only to get a view of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "      self.df = None\n",
    "\n",
    "      print(\"==========================================\")\n",
    "      print(\"Data\")\n",
    "      print(\"==========================================\")\n",
    "\n",
    "  def load_data(self):\n",
    "    \"\"\"\n",
    "      Loads data from csv file\n",
    "    \"\"\"\n",
    "    print(\"[*] Loading Data\")\n",
    "\n",
    "    # data file path\n",
    "    data_file = os.path.join(input_dir, 'relevance_sample_data.csv')\n",
    "    \n",
    "    # read data\n",
    "    self.df = pd.read_csv(data_file)\n",
    "\n",
    "\n",
    "  def _text_to_dict(self, text):\n",
    "    \"\"\"\n",
    "    Converts a text string into a dictionary.\n",
    "\n",
    "    :param text: A string representation of a dictionary.\n",
    "    :return: A dictionary object if conversion is successful, otherwise {}.\n",
    "    \"\"\"\n",
    "    try:\n",
    "      return ast.literal_eval(text)\n",
    "    except:\n",
    "      return {}  # Return an empty dictionary in case of an error\n",
    "    \n",
    "  def _dict_to_paragraphs(self, dictionary):\n",
    "    \"\"\"\n",
    "    Converts a dictionary into a string of paragraphs.\n",
    "\n",
    "    :param dictionary: A dictionary.\n",
    "    :return: A string composed of paragraphs based on the dictionary's key-value pairs.\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i, (k, v) in enumerate(dictionary.items()):\n",
    "        text += k.capitalize() + '\\n' + v + '\\n'\n",
    "    return text\n",
    "  \n",
    "  def transfrom_data(self):\n",
    "\n",
    "    print(\"[*] Transforming Data\")\n",
    "    \n",
    "    # Convert to dictionary\n",
    "    self.df['most_relevant_dict'] = self.df['most_relevant'].apply(self._text_to_dict)\n",
    "    self.df['second_most_relevant_dict'] = self.df['second_most_relevant'].apply(self._text_to_dict)\n",
    "    self.df['second_least_relevant_dict'] = self.df['second_least_relevant'].apply(self._text_to_dict)\n",
    "    self.df['least_relevant_dict'] = self.df['least_relevant'].apply(self._text_to_dict)\n",
    "\n",
    "\n",
    "    # Convert from dictionary to text\n",
    "    self.df['most_relevant_text'] = self.df['most_relevant_dict'].apply(self._dict_to_paragraphs)\n",
    "    self.df['second_most_relevant_text'] = self.df['second_most_relevant_dict'].apply(self._dict_to_paragraphs)\n",
    "    self.df['second_least_relevant_text'] = self.df['second_least_relevant_dict'].apply(self._dict_to_paragraphs)\n",
    "    self.df['least_relevant_text'] = self.df['least_relevant_dict'].apply(self._dict_to_paragraphs)\n",
    "\n",
    "\n",
    "  def _get_embeddings(self, text1, text2):\n",
    "    \"\"\"\n",
    "    Generates embeddings for two texts.\n",
    "\n",
    "    :param text1: First text string.\n",
    "    :param text2: Second text string.\n",
    "    :return: Tuple of embeddings for text1 and text2.\n",
    "    \"\"\"\n",
    "    embedding1 = self.embeddings_model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = self.embeddings_model.encode(text2, convert_to_tensor=True)\n",
    "    return embedding1.cpu(), embedding2.cpu()\n",
    "  \n",
    "  def prepare_data(self):\n",
    "\n",
    "    print(\"[*] Prepare Data for Training\")\n",
    "    \n",
    "    model_name = 'paraphrase-MiniLM-L6-v2'\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    self.embeddings_model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    # Create embeddings for each pair\n",
    "    self.df['most_relevant_embeddings'] = self.df.progress_apply(lambda row: self._get_embeddings(row['prompt'], row['most_relevant_text']), axis=1)\n",
    "    self.df['second_most_relevant_embeddings'] = self.df.progress_apply(lambda row: self._get_embeddings(row['prompt'], row['second_most_relevant_text']), axis=1)\n",
    "    self.df['second_least_relevant_embeddings'] = self.df.progress_apply(lambda row: self._get_embeddings(row['prompt'], row['second_least_relevant_text']), axis=1)\n",
    "    self.df['least_relevant_embeddings'] = self.df.progress_apply(lambda row: self._get_embeddings(row['prompt'], row['least_relevant_text']), axis=1)\n",
    "\n",
    "    # Label the Data\n",
    "    self.df['most_relevant_label'] = 3\n",
    "    self.df['second_most_relevant_label'] = 2\n",
    "    self.df['second_least_relevant_label'] = 1\n",
    "    self.df['least_relevant_label'] = 0\n",
    "\n",
    "    X = self.df['most_relevant_embeddings'].tolist() + self.df['second_most_relevant_embeddings'].tolist() + self.df['second_least_relevant_embeddings'].tolist() + self.df['least_relevant_embeddings'].tolist()\n",
    "    y = self.df['most_relevant_label'].tolist() + self.df['second_most_relevant_label'].tolist() + self.df['second_least_relevant_label'].tolist() + self.df['least_relevant_label'].tolist()\n",
    "\n",
    "    # Convert embeddings from tuples to concatenated arrays\n",
    "    X = [torch.abs(embeddings[0] - embeddings[1]).numpy() for embeddings in X]\n",
    "\n",
    "    # Shuffle X and y\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    # train test split\n",
    "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "  def get_train_data(self):\n",
    "    return self.X_train, self.y_train\n",
    "  \n",
    "  def get_test_data(self):\n",
    "    return self.X_test, self.y_test\n",
    "  \n",
    "  def show_random_sample(self):\n",
    "    random_sample_index = np.random.randint(0, len(self.df))\n",
    "\n",
    "    print(\"Prompt:\\n\", self.df.iloc[random_sample_index]['prompt'], \"...\\n\")\n",
    "    print(\"Most Relevant Text:\\n\", self.df.iloc[random_sample_index]['most_relevant_text'][:300], \"...\\n\")\n",
    "    print(\"Second Most Relevant Text:\\n\", self.df.iloc[random_sample_index]['second_most_relevant_text'][:300], \"...\\n\")\n",
    "    print(\"Second Least Relevant Text:\\n\", self.df.iloc[random_sample_index]['second_least_relevant_text'][:300], \"...\\n\")\n",
    "    print(\"Least Relevant Text:\\n\", self.df.iloc[random_sample_index]['least_relevant_text'][:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Data\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Initilaize data\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading Data\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Transforming Data\n"
     ]
    }
   ],
   "source": [
    "# transform data\n",
    "data.transfrom_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Prepare Data for Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54b898d63c14218bccc54f29390c446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605f6f165acc44ea886766ebfdb6754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab29c91613384e81a8007e5f33804b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ac382f07a94a0ab9791ca7bf6d6c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " Write a systematic survey or overview about the impact of transcendental empiricism on the study and interpretation of art history, including the critique of traditional linear and teleological conceptions of history and the implications for art historical knowledge, methodology, and politics. ...\n",
      "\n",
      "Most Relevant Text:\n",
      " Title\n",
      "Istorija (umetnosti) u uslovima transcendentalnog empirizma / (Art) History under the Conditions of Transcendental Empiricism\n",
      "Abstract\n",
      "This text deals with a critique of molar conception of history and, particularly, art history. Instead of conceptualizing history as linear and teleological, t ...\n",
      "\n",
      "Second Most Relevant Text:\n",
      " Title\n",
      "The Work of Art that Stands Alone\n",
      "Abstract\n",
      "In ‘From Work to Text’ – Roland Barthes’ classic manifesto that spelled the end of any closed structuralism and opened the text to as many forces, connections and actualisations as possible – Barthes suggests that the closed work is the very death of  ...\n",
      "\n",
      "Second Least Relevant Text:\n",
      " Title\n",
      "Proof and Persuasion in Black Athena: The Case of K. O. Muller\n",
      "Abstract\n",
      "When in 1824 the German classical scholar Karl Otfried Muller (17971840) set down to write a review of Champollion's first Letter to M. Dacier (1822), he was profoundly interested.' For several years he had been working on ...\n",
      "\n",
      "Least Relevant Text:\n",
      " Title\n",
      "Excavation of a post-medieval settlement at Druim nan Dearcag, and related sites around Loch Olaphat, North Uist\n",
      "Abstract\n",
      "The loch-side settlement of Druim nan Dearcag has been shown by excavation to date to the 16th-17th centuries AD, when it formed part of a dispersed settlement pattern in n ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show random sample from data\n",
    "data.show_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train test data\n",
    "# X_train, y_train, X_test, Y_test = data.get_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Visualize\n",
    "***\n",
    "TODOs:\n",
    "- visualize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualize():\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        print(\"==========================================\")\n",
    "        print(\"Visualize\")\n",
    "        print(\"==========================================\")\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "\n",
    "    def visualize_data(self):\n",
    "        print(\"Implement this function\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Visualize\n",
      "==========================================\n",
      "Implement this function\n"
     ]
    }
   ],
   "source": [
    "# Initilaize Visualize\n",
    "visualize = Visualize(data=data)\n",
    "visualize.visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Import Submission Model\n",
    "***\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: initializes classifier\n",
    "- `fit`: gets train data and labels as input to train the classifier\n",
    "- `predict`: gets test data and outputs predictions made by the trained classifier\n",
    "\n",
    "\n",
    "In this example code, the `Model` class implements a Gradient Boosting Classifier model. You can find the code in `M1-Challenge-Class-2024/Relevance/Starting_Kit/sample_code_submission/model.py`. You can modify it the way you want, keeping the required class structure and functions there. More instructions are given inside the `model.py` file. If running in Collab, click the folder icon in the left sidebar to open the file browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Program\n",
    "***\n",
    "**`Ingestion program`** is responsible to run the submission of a participant on Codabench platform. **`Program`** is a simplified version of the **Ingestion Program** to show to participants how it runs a submission.\n",
    "1. Train a model on train data\n",
    "2. Predict using Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        # used to keep object of Model class to run the submission\n",
    "        self.model = None\n",
    "        # object of Data class used here to get the train and test sets\n",
    "        self.data = data\n",
    "\n",
    "        # results\n",
    "        self.results = []\n",
    "\n",
    "        print(\"==========================================\")\n",
    "        print(\"Program\")\n",
    "        print(\"==========================================\")\n",
    "    \n",
    "    def initialize_submission(self):\n",
    "        print(\"[*] Initializing Submmited Model\")\n",
    "        self.model = Model()\n",
    "\n",
    "    def fit_submission(self):\n",
    "        print(\"[*] Calling fit method of submitted model\")\n",
    "        X_train, y_train  = self.data.get_train_data()\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    def predict_submission(self):\n",
    "        print(\"[*] Calling predict method of submitted model\")\n",
    "      \n",
    "        X_test, _ = self.data.get_test_data()\n",
    "        self.y_test_hat = self.model.predict(X_test)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Program\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Intiialize Program\n",
    "program = Program(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Initializing Submmited Model\n",
      "[*] - Initializing Classifier\n"
     ]
    }
   ],
   "source": [
    "# Initialize submitted model\n",
    "program.initialize_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Calling fit method of submitted model\n",
      "[*] - Training Classifier on the train set\n"
     ]
    }
   ],
   "source": [
    "# Call fit method of submitted model\n",
    "program.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Calling predict method of submitted model\n",
      "[*] - Predicting test set using trained Classifier\n"
     ]
    }
   ],
   "source": [
    "# Call predict method of submitted model\n",
    "program.predict_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Score\n",
    "***\n",
    "\n",
    "TODOs:\n",
    "- Explain the evaluation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score():\n",
    "\n",
    "    def __init__(self, data, program):\n",
    "\n",
    "        self.data = data\n",
    "        self.program = program\n",
    "\n",
    "        print(\"==========================================\")\n",
    "        print(\"Score\")\n",
    "        print(\"==========================================\")\n",
    "\n",
    "    def compute_scores(self):\n",
    "        print(\"[*] Computing scores\")\n",
    "\n",
    "        _, y_test = self.data.get_test_data()\n",
    "        y_test_hat = self.program.y_test_hat\n",
    "\n",
    "        # Classification report\n",
    "        print(classification_report(y_test, y_test_hat))\n",
    "\n",
    "        k_tau, _ = kendalltau(y_test, y_test_hat)\n",
    "        print(f\"Kendall's Tau: {k_tau}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Score\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize Score\n",
    "score = Score(data=data, program=program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Computing scores\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.53        96\n",
      "           1       0.55      0.51      0.53       107\n",
      "           2       0.58      0.62      0.60        91\n",
      "           3       0.77      0.75      0.76       106\n",
      "\n",
      "    accuracy                           0.60       400\n",
      "   macro avg       0.60      0.60      0.60       400\n",
      "weighted avg       0.61      0.60      0.61       400\n",
      "\n",
      "Kendall's Tau: 0.705678403820533\n"
     ]
    }
   ],
   "source": [
    "# Compute Score\n",
    "score.compute_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Submissions\n",
    "***\n",
    "\n",
    "### **Unit Testing**\n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission.\n",
    "<br>\n",
    "Keep the sample code simple.<br>\n",
    "\n",
    "<code>python3</code> is required for this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Ingestion Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "### Ingestion Program\n",
      "############################################\n",
      "\n",
      "[*] Loading Data\n",
      "[*] Transforming Data\n",
      "[*] Prepare Data for Training\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "[*] Initializing Submmited Model\n",
      "[*] - Initializing Classifier\n",
      "[*] Calling fit method of submitted model\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ihsanullah/Desktop/ParisSaclay/Challenge Class/2024/ClassRepo/Relevance/Starting_Kit/./ingestion_program/ingestion.py\", line 230, in <module>\n",
      "    ingestion.fit_submission()\n",
      "  File \"/Users/ihsanullah/Desktop/ParisSaclay/Challenge Class/2024/ClassRepo/Relevance/Starting_Kit/./ingestion_program/ingestion.py\", line 185, in fit_submission\n",
      "    X_train, y_train  = self.data.get_train_data()\n",
      "AttributeError: 'Ingestion' object has no attribute 'data'\n"
     ]
    }
   ],
   "source": [
    "!python3 $program_dir/ingestion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Scoring Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $score_dir/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare the submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "code_submission = 'Relevance-code_submission_' + the_date + '.zip'\n",
    "zipdir(code_submission, submission_dir)\n",
    "print(\"Submit : \" + code_submission + \" to the competition\")\n",
    "print(\"You can find the zip file in `M1-Challenge-Class-2024/Relevance/Starting_Kit/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9e001b0608738f9411416229c98988c04b997dc526fb61c5e4e084e768e3249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
